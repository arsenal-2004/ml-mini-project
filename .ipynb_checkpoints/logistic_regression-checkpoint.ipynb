{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and temporal scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2223: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2225: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2233: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] /= 2  # halve the component at -N/2\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2234: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  temp = Y[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2236: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = temp  # set that equal to the component at -N/2\n"
     ]
    }
   ],
   "source": [
    "X, y, class_names = preprocessing.create_data_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X: (2565, 22, 57)\n",
      "Possible Classes: dict_values(['make', 'polite', 'draw', 'soon', 'money', 'cost', 'when', 'innocent', 'pen', 'name', 'know', 'paper', 'no', 'I', 'tray', 'research', 'computer_PC_', 'ready', 'God', 'what', 'wait_notyet_', 'building', 'yes', 'different', 'sad', 'man', 'right', 'later', 'all', 'hurry', 'his_hers', 'hear', 'danger', 'eat', 'drink', 'share', 'thank', 'you', 'temper', 'juice', 'hurt', 'wild', 'please', 'give', 'come', 'glove', 'forget', 'more', 'which', 'shop', 'lose', 'maybe', 'stubborn', 'question', 'where', 'sorry', 'spend', 'girl', 'Norway', 'write', 'science', 'zero', 'buy', 'happy', 'hot', 'not', 'take', 'will', 'head', 'go', 'is_true_', 'think', 'why', 'deaf', 'answer', 'surprise', 'how', 'read', 'love', 'flash', 'boy', 'voluntary', 'hello', 'cold', 'change_mind_', 'mine', 'crazy', 'responsible', 'who', 'joke', 'same', 'wrong', 'alive', 'us', 'exit'])\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of X:', X.shape)\n",
    "print('Possible Classes:', class_names.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X after flattening:  (2565, 1254)\n"
     ]
    }
   ],
   "source": [
    "X_flat = preprocessing.flatten_data(X)\n",
    "print('Dimensions of X after flattening: ', X_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimensions:  (1795, 1254)\n",
      "Test set dimensions:  (770, 1254)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.3)\n",
    "print('Training set dimensions: ', X_train.shape)\n",
    "print('Test set dimensions: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(C=10.0, max_iter=100)\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = log_reg_model.predict(X_train)\n",
    "y_test_predict = log_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:  1.0\n",
      "Test Set Accuracy:  0.9337662337662338\n"
     ]
    }
   ],
   "source": [
    "print('Training Set Accuracy: ', metrics.accuracy_score(y_train, y_train_predict))\n",
    "print('Test Set Accuracy: ', metrics.accuracy_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      0.45      0.62        11\n",
      "           3       0.67      1.00      0.80         8\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       0.89      0.73      0.80        11\n",
      "           7       1.00      0.67      0.80         9\n",
      "           8       0.78      0.88      0.82         8\n",
      "           9       0.89      1.00      0.94         8\n",
      "          10       1.00      0.88      0.93         8\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       0.86      1.00      0.92         6\n",
      "          13       1.00      0.71      0.83         7\n",
      "          14       1.00      1.00      1.00         9\n",
      "          15       1.00      0.89      0.94         9\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         7\n",
      "          18       1.00      1.00      1.00         7\n",
      "          19       1.00      0.80      0.89        10\n",
      "          20       1.00      1.00      1.00        11\n",
      "          21       1.00      1.00      1.00         6\n",
      "          22       0.90      1.00      0.95         9\n",
      "          23       1.00      1.00      1.00         7\n",
      "          24       1.00      0.86      0.92         7\n",
      "          25       1.00      0.67      0.80         9\n",
      "          26       1.00      1.00      1.00        12\n",
      "          27       1.00      0.88      0.93         8\n",
      "          28       1.00      1.00      1.00         9\n",
      "          29       1.00      0.89      0.94         9\n",
      "          30       1.00      1.00      1.00        11\n",
      "          31       1.00      1.00      1.00         6\n",
      "          32       0.82      1.00      0.90         9\n",
      "          33       0.90      0.90      0.90        10\n",
      "          34       0.90      1.00      0.95         9\n",
      "          35       1.00      0.86      0.92         7\n",
      "          36       1.00      1.00      1.00         7\n",
      "          37       1.00      0.90      0.95        10\n",
      "          38       1.00      1.00      1.00         9\n",
      "          39       1.00      1.00      1.00         7\n",
      "          40       1.00      0.78      0.88         9\n",
      "          41       1.00      1.00      1.00         7\n",
      "          42       0.80      1.00      0.89         8\n",
      "          43       1.00      1.00      1.00        10\n",
      "          44       1.00      1.00      1.00         6\n",
      "          45       0.90      1.00      0.95         9\n",
      "          46       1.00      0.91      0.95        11\n",
      "          47       1.00      0.89      0.94         9\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       1.00      0.88      0.93         8\n",
      "          50       0.92      1.00      0.96        12\n",
      "          51       0.67      1.00      0.80         4\n",
      "          52       1.00      1.00      1.00        11\n",
      "          53       1.00      0.90      0.95        10\n",
      "          54       1.00      1.00      1.00        11\n",
      "          55       0.86      1.00      0.92         6\n",
      "          56       1.00      1.00      1.00         7\n",
      "          57       1.00      0.86      0.92         7\n",
      "          58       1.00      1.00      1.00         4\n",
      "          59       0.86      1.00      0.92         6\n",
      "          60       0.67      1.00      0.80         2\n",
      "          61       0.70      0.88      0.78         8\n",
      "          62       1.00      0.86      0.92         7\n",
      "          63       0.90      1.00      0.95         9\n",
      "          64       1.00      0.90      0.95        10\n",
      "          65       1.00      1.00      1.00         8\n",
      "          66       1.00      1.00      1.00         6\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       0.90      1.00      0.95         9\n",
      "          69       1.00      1.00      1.00         7\n",
      "          70       1.00      0.89      0.94         9\n",
      "          71       0.75      1.00      0.86         9\n",
      "          72       1.00      1.00      1.00         4\n",
      "          73       1.00      0.91      0.95        11\n",
      "          74       0.90      1.00      0.95         9\n",
      "          75       0.80      1.00      0.89         4\n",
      "          76       0.86      0.86      0.86         7\n",
      "          77       0.50      1.00      0.67         6\n",
      "          78       0.88      1.00      0.93         7\n",
      "          79       1.00      1.00      1.00         8\n",
      "          80       0.80      0.67      0.73         6\n",
      "          81       1.00      1.00      1.00         8\n",
      "          82       1.00      1.00      1.00        16\n",
      "          83       1.00      1.00      1.00        10\n",
      "          84       0.89      0.89      0.89         9\n",
      "          85       0.50      1.00      0.67         4\n",
      "          86       0.91      0.77      0.83        13\n",
      "          87       1.00      1.00      1.00        11\n",
      "          88       1.00      0.73      0.84        11\n",
      "          89       1.00      1.00      1.00         6\n",
      "          90       0.88      1.00      0.93         7\n",
      "          91       1.00      1.00      1.00         9\n",
      "          92       0.86      1.00      0.92         6\n",
      "          93       0.88      1.00      0.93         7\n",
      "          94       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       770\n",
      "   macro avg       0.94      0.94      0.93       770\n",
      "weighted avg       0.95      0.93      0.93       770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51cdccfba8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.imshow(confusion_matrix(y_test, y_test_predict))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
