{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimit\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:2223: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "C:\\Users\\jimit\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:2225: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "C:\\Users\\jimit\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:2233: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] /= 2  # halve the component at -N/2\n",
      "C:\\Users\\jimit\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:2234: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  temp = Y[sl]\n",
      "C:\\Users\\jimit\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:2236: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = temp  # set that equal to the component at -N/2\n"
     ]
    }
   ],
   "source": [
    "X, y, class_names = preprocessing.create_data_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = preprocessing.flatten_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, dummy_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "    # create model\n",
    "# def baseline_model():\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=1254, activation='relu'))\n",
    "model.add(Dense(95, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = KerasClassifier(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(500, input_dim=1254, activation='relu'))\n",
    "# model.add(Dense(95, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2052/2052 [==============================] - 5s 2ms/step - loss: 3.6777 - acc: 0.1501\n",
      "Epoch 2/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 2.0201 - acc: 0.4800\n",
      "Epoch 3/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 1.2488 - acc: 0.6540\n",
      "Epoch 4/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.8416 - acc: 0.7753\n",
      "Epoch 5/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.6068 - acc: 0.8441\n",
      "Epoch 6/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.4567 - acc: 0.8860\n",
      "Epoch 7/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.3825 - acc: 0.9020\n",
      "Epoch 8/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.2929 - acc: 0.9259\n",
      "Epoch 9/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.2486 - acc: 0.9376\n",
      "Epoch 10/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.1988 - acc: 0.9586\n",
      "Epoch 11/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.1932 - acc: 0.9474\n",
      "Epoch 12/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.1771 - acc: 0.9557\n",
      "Epoch 13/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.1343 - acc: 0.9703\n",
      "Epoch 14/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.1065 - acc: 0.9761\n",
      "Epoch 15/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.1129 - acc: 0.9698\n",
      "Epoch 16/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0864 - acc: 0.9815\n",
      "Epoch 17/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0755 - acc: 0.9825\n",
      "Epoch 18/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0810 - acc: 0.9800\n",
      "Epoch 19/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.0754 - acc: 0.9844\n",
      "Epoch 20/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.0732 - acc: 0.9829\n",
      "Epoch 21/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.0579 - acc: 0.9864\n",
      "Epoch 22/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0398 - acc: 0.9932\n",
      "Epoch 23/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0496 - acc: 0.9903\n",
      "Epoch 24/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0506 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0799 - acc: 0.9756\n",
      "Epoch 26/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0573 - acc: 0.9873\n",
      "Epoch 27/30\n",
      "2052/2052 [==============================] - 3s 2ms/step - loss: 0.0343 - acc: 0.9932\n",
      "Epoch 28/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0486 - acc: 0.9849\n",
      "Epoch 29/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0342 - acc: 0.9907\n",
      "Epoch 30/30\n",
      "2052/2052 [==============================] - 3s 1ms/step - loss: 0.0179 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec90167358>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/513 [==============================] - 0s 927us/step\n",
      "\n",
      "acc: 94.74%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 96.18% (1.46%)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "results = cross_val_score(estimator, X_flat, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
