{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and temporal scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2223: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2225: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2233: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] /= 2  # halve the component at -N/2\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2234: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  temp = Y[sl]\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/scipy/signal/signaltools.py:2236: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = temp  # set that equal to the component at -N/2\n"
     ]
    }
   ],
   "source": [
    "X, y, class_names = preprocessing.create_data_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X: (2565, 22, 57)\n",
      "Possible Classes: dict_values(['make', 'polite', 'draw', 'soon', 'money', 'cost', 'when', 'innocent', 'pen', 'name', 'know', 'paper', 'no', 'I', 'tray', 'research', 'computer_PC_', 'ready', 'God', 'what', 'wait_notyet_', 'building', 'yes', 'different', 'sad', 'man', 'right', 'later', 'all', 'hurry', 'his_hers', 'hear', 'danger', 'eat', 'drink', 'share', 'thank', 'you', 'temper', 'juice', 'hurt', 'wild', 'please', 'give', 'come', 'glove', 'forget', 'more', 'which', 'shop', 'lose', 'maybe', 'stubborn', 'question', 'where', 'sorry', 'spend', 'girl', 'Norway', 'write', 'science', 'zero', 'buy', 'happy', 'hot', 'not', 'take', 'will', 'head', 'go', 'is_true_', 'think', 'why', 'deaf', 'answer', 'surprise', 'how', 'read', 'love', 'flash', 'boy', 'voluntary', 'hello', 'cold', 'change_mind_', 'mine', 'crazy', 'responsible', 'who', 'joke', 'same', 'wrong', 'alive', 'us', 'exit'])\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of X:', X.shape)\n",
    "print('Possible Classes:', class_names.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X after flattening:  (2565, 1254)\n"
     ]
    }
   ],
   "source": [
    "X_flat = preprocessing.flatten_data(X)\n",
    "print('Dimensions of X after flattening: ', X_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dimensions:  (1795, 1254)\n",
      "Test set dimensions:  (770, 1254)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.3)\n",
    "print('Training set dimensions: ', X_train.shape)\n",
    "print('Test set dimensions: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/parth/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(C=10.0, max_iter=100)\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = log_reg_model.predict(X_train)\n",
    "y_test_predict = log_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:  1.0\n",
      "Test Set Accuracy:  0.938961038961039\n"
     ]
    }
   ],
   "source": [
    "print('Training Set Accuracy: ', metrics.accuracy_score(y_train, y_train_predict))\n",
    "print('Test Set Accuracy: ', metrics.accuracy_score(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.91      0.83      0.87        12\n",
      "           3       0.67      0.86      0.75         7\n",
      "           4       1.00      0.92      0.96        12\n",
      "           5       0.78      0.88      0.82         8\n",
      "           6       0.71      1.00      0.83         5\n",
      "           7       0.88      0.78      0.82         9\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       1.00      1.00      1.00         8\n",
      "          10       1.00      0.75      0.86         4\n",
      "          11       1.00      1.00      1.00         4\n",
      "          12       1.00      1.00      1.00         6\n",
      "          13       1.00      0.75      0.86         8\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         8\n",
      "          17       1.00      1.00      1.00         7\n",
      "          18       1.00      0.92      0.96        13\n",
      "          19       0.86      1.00      0.92         6\n",
      "          20       1.00      1.00      1.00        13\n",
      "          21       1.00      1.00      1.00         9\n",
      "          22       1.00      0.86      0.92         7\n",
      "          23       1.00      1.00      1.00        10\n",
      "          24       0.83      0.71      0.77         7\n",
      "          25       0.86      0.67      0.75         9\n",
      "          26       1.00      1.00      1.00        11\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       0.75      1.00      0.86         6\n",
      "          29       1.00      1.00      1.00         9\n",
      "          30       1.00      1.00      1.00        12\n",
      "          31       1.00      1.00      1.00         8\n",
      "          32       1.00      0.86      0.92         7\n",
      "          33       1.00      1.00      1.00         8\n",
      "          34       1.00      1.00      1.00         8\n",
      "          35       1.00      1.00      1.00         8\n",
      "          36       1.00      1.00      1.00         8\n",
      "          37       0.90      1.00      0.95         9\n",
      "          38       1.00      1.00      1.00         8\n",
      "          39       1.00      0.90      0.95        10\n",
      "          40       0.83      1.00      0.91         5\n",
      "          41       0.92      1.00      0.96        12\n",
      "          42       0.78      1.00      0.88         7\n",
      "          43       0.88      1.00      0.93         7\n",
      "          44       0.88      0.78      0.82         9\n",
      "          45       0.86      1.00      0.92         6\n",
      "          46       1.00      1.00      1.00         4\n",
      "          47       1.00      1.00      1.00        10\n",
      "          48       0.50      1.00      0.67         1\n",
      "          49       1.00      0.78      0.88         9\n",
      "          50       1.00      0.91      0.95        11\n",
      "          51       1.00      0.73      0.84        11\n",
      "          52       1.00      1.00      1.00         5\n",
      "          53       1.00      0.90      0.95        10\n",
      "          54       0.92      1.00      0.96        11\n",
      "          55       1.00      1.00      1.00         4\n",
      "          56       1.00      1.00      1.00         8\n",
      "          57       1.00      0.80      0.89         5\n",
      "          58       1.00      1.00      1.00         7\n",
      "          59       1.00      1.00      1.00        13\n",
      "          60       1.00      1.00      1.00         6\n",
      "          61       0.90      1.00      0.95         9\n",
      "          62       0.89      1.00      0.94         8\n",
      "          63       0.89      1.00      0.94         8\n",
      "          64       1.00      1.00      1.00         8\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       0.75      0.86      0.80         7\n",
      "          67       1.00      1.00      1.00        11\n",
      "          68       1.00      1.00      1.00        10\n",
      "          69       1.00      1.00      1.00         6\n",
      "          70       1.00      1.00      1.00         5\n",
      "          71       0.75      0.75      0.75         8\n",
      "          72       1.00      1.00      1.00         8\n",
      "          73       1.00      0.91      0.95        11\n",
      "          74       1.00      1.00      1.00         9\n",
      "          75       0.86      1.00      0.92         6\n",
      "          76       1.00      0.83      0.91         6\n",
      "          77       0.83      0.83      0.83         6\n",
      "          78       1.00      1.00      1.00         6\n",
      "          79       1.00      1.00      1.00         9\n",
      "          80       0.50      1.00      0.67         6\n",
      "          81       1.00      1.00      1.00        14\n",
      "          82       1.00      1.00      1.00        13\n",
      "          83       0.92      1.00      0.96        11\n",
      "          84       1.00      0.88      0.93         8\n",
      "          85       0.73      0.73      0.73        11\n",
      "          86       1.00      0.44      0.62         9\n",
      "          87       1.00      1.00      1.00         8\n",
      "          88       0.86      0.75      0.80         8\n",
      "          89       0.90      1.00      0.95         9\n",
      "          90       1.00      1.00      1.00         8\n",
      "          91       1.00      1.00      1.00        11\n",
      "          92       1.00      1.00      1.00         8\n",
      "          93       1.00      1.00      1.00         8\n",
      "          94       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       770\n",
      "   macro avg       0.94      0.94      0.93       770\n",
      "weighted avg       0.95      0.94      0.94       770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7703383cf8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.imshow(confusion_matrix(y_test, y_test_predict), cmap=cm.Blues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
