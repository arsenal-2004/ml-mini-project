# Sign Language Recognition using Sensors
In this project, we explore various techniques for the classification of various signs from sensor data obtained using non-intrusive methods such as gloves or armbands.

This project is largely based upon the implementation of the paper written by **H. Cate**, **F. Dalvi** and **Z. Hussain**. The link for their paper "Sign Language Recognition Using Temporal Classification" can be found [here](https://arxiv.org/abs/1701.01875#). Whenever we were stuck at some point or needed guidance on how to proceed further, we have referred to their [codebase](https://github.com/fdalvi/ASLtoSpeech). We have been standing on the shoulders of giants, and we would like to thank them.

The various methods which we have implemented are:
1) [Logistic Regression](https://github.com/arsenal-2004/ml-mini-project/blob/master/logistic_regression.ipynb)
2) [Support Vector Machines](https://github.com/arsenal-2004/ml-mini-project/blob/master/svm.ipynb) (tuned using Grid Search)
3) [Artificial Neural Networks](https://github.com/arsenal-2004/ml-mini-project/blob/master/simple_neural.ipynb) (3 layers)
4) [Long Short-Term Memory](https://github.com/arsenal-2004/ml-mini-project/blob/master/lstm.ipynb)

[This](https://docs.google.com/document/d/1fEc0GqhpSC-FLvwmb1FlhJTgknsimgnRUur65X9nfRg/edit?usp=sharing) is the report for our work. The results that we have obtained and the analysis for the same can be found there.

The contributors to this project are:
1) [Parth Doshi](https://github.com/arsenal-2004)
2) [Jimit Gandhi](https://github.com/jimitgandhi)
3) [Deep Gosalia](https://github.com/deepgosalia1)
