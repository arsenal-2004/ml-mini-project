# Sign Language Recognition using Sensors
In this project, we explore various techniques for the classification of various signs from sensor data obtained using non-intrusive methods such as gloves or armbands.

This project is largely based upon the implementation of the paper written by H. Cate, F. Dalvi and Z. Hussain. The link for their paper "Sign Language Recognition Using Temporal Classification" can be found [here](https://arxiv.org/abs/1701.01875#). Whenever we were stuck at some point or needed guidance on how to proceed further, we have referred to their [codebase](https://github.com/fdalvi/ASLtoSpeech). We have been standing on the shoulders of giants, and we would like to thank them.

The various methods which we have implemented are:
1) Logistic Regression
2) Support Vector Machines (tuned using Grid Search)
3) Artificial Neural Networks (3 layers)
4) Long Short-Term Memory

[This](https://docs.google.com/document/d/1fEc0GqhpSC-FLvwmb1FlhJTgknsimgnRUur65X9nfRg/edit?usp=sharing) is the report for our work. The results that we have obtained and the analysis for the same can be found there.

